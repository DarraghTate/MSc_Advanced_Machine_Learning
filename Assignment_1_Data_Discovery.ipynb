{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "MLEnv",
      "language": "python",
      "name": "mlenv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    },
    "colab": {
      "name": "Assignment_1_Data_Discovery.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DarraghTate/MSc_Advanced_Machine_Learning/blob/main/Assignment_1_Data_Discovery.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "premier-mitchell",
        "outputId": "334a96d0-4fff-45e3-b999-63c2b4f31957"
      },
      "source": [
        "! pip install pandas\n",
        "! pip install sklearn\n",
        "! pip install numpy\n",
        "! pip install pydrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "downloaded = drive.CreateFile({'id':\"1Lg8a476HB7bSB2gKLv15eanBkHsPU9SD\"})\n",
        "downloaded.GetContentFile('diamonds.csv') \n",
        "import pandas as pd\n",
        "\n",
        "# Used to set random states, for consistency\n",
        "random_state = 23\n",
        "# https://drive.google.com/file/d/1Lg8a476HB7bSB2gKLv15eanBkHsPU9SD/view?usp=sharing\n",
        "# 1Lg8a476HB7bSB2gKLv15eanBkHsPU9SD\n",
        "df = pd.read_csv('diamonds.csv')\n",
        "\n",
        "df = df[[\"carat\",\"cut\",\"color\",\"clarity\",\"depth\",\"table\",\"price\",\"x\",\"y\",\"z\"]]\n",
        "# .astype is pandas categorisation function.\n",
        "df[['cut', 'color', 'clarity']] = df[['cut', 'color', 'clarity']].astype('category')\n",
        "# .cat.codes is pandas function to take the categorical information and replace the string variables with the numerics\n",
        "df['cut'] = df['cut'].cat.codes\n",
        "df['color'] = df['color'].cat.codes\n",
        "df['clarity'] = df['clarity'].cat.codes\n",
        "\n",
        "# x is the dataframe conaining the independant variables\n",
        "X_values = df[[\"carat\",\"cut\",\"color\",\"clarity\",\"depth\",\"table\",\"x\",\"y\",\"z\"]]\n",
        "# y is the dataframe containing the dependant variables\n",
        "y_values = df['price']\n",
        "\n",
        "categories = pd.qcut(y_values, 10)\n",
        "\n",
        "y_categorical = pd.DataFrame(y_values, columns={'price'})\n",
        "\n",
        "y_categorical.loc[(y_categorical['price']<500), \"categories\"] = \"< 500\"\n",
        "y_categorical.loc[(y_categorical['price']>=500) & (y_categorical['price']<1000), 'categories'] = \"500 - 1000\"\n",
        "y_categorical.loc[(y_categorical['price']>=1000) & (y_categorical['price']<1500), 'categories'] = \"1000 - 1500\"\n",
        "y_categorical.loc[(y_categorical['price']>=1500) & (y_categorical['price']<2000), 'categories'] = \"1500 - 2000\"\n",
        "y_categorical.loc[(y_categorical['price']>=2000) & (y_categorical['price']<2500), 'categories'] = \"2000 - 2500\"\n",
        "y_categorical.loc[(y_categorical['price']>=2500) & (y_categorical['price']<3000), 'categories'] = \"2500 - 3000\"\n",
        "y_categorical.loc[(y_categorical['price']>=3000) & (y_categorical['price']<3500), 'categories'] = \"3000 - 3500\"\n",
        "#y_categorical.loc[(y_categorical['price']>=3500) & (y_categorical['price']<4000), 'categories'] = \"3500 - 4000\"\n",
        "#y_categorical.loc[(y_categorical['price']>=4000), \"categories\"] = \"4000+\"\n",
        "y_categorical.loc[(y_categorical['price']>=3500), \"categories\"] = \"3500+\""
      ],
      "id": "premier-mitchell",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.0.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n",
            "Requirement already satisfied: pydrive in /usr/local/lib/python3.7/dist-packages (1.3.1)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.7/dist-packages (from pydrive) (3.13)\n",
            "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.7/dist-packages (from pydrive) (1.12.8)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pydrive) (4.1.3)\n",
            "Requirement already satisfied: google-auth>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->pydrive) (1.28.0)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->pydrive) (1.26.2)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->pydrive) (0.17.4)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->pydrive) (3.0.1)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->pydrive) (0.0.4)\n",
            "Requirement already satisfied: six<2dev,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->pydrive) (1.15.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from oauth2client>=4.0.0->pydrive) (0.2.8)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client>=4.0.0->pydrive) (0.4.8)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from oauth2client>=4.0.0->pydrive) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.2->pydrive) (4.2.1)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.2->pydrive) (54.2.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->pydrive) (1.53.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->pydrive) (20.9)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->pydrive) (2018.9)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->pydrive) (3.12.4)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->pydrive) (2.23.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->pydrive) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->pydrive) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->pydrive) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->pydrive) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->pydrive) (1.24.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "existing-three",
        "outputId": "48223d2d-f3bf-4576-de14-32eba879fbed"
      },
      "source": [
        "# Linear Regression / Polynomial Regression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "linear_model = LinearRegression(copy_X = True, fit_intercept = True, n_jobs = None, normalize = False)\n",
        "linear_model.fit(X_values, y_values)\n",
        "y_pred= linear_model.predict(X_values)\n",
        "score = r2_score(y_values, y_pred)\n",
        "print(f\"R squared (No polynomials): {score:.5f}\\n\")\n",
        "\n",
        "degree = 4\n",
        "poly_reg_model = PolynomialFeatures(degree = degree)\n",
        "X_poly = poly_reg_model.fit_transform(X_values)\n",
        "polynomial_model = LinearRegression()\n",
        "polynomial_model.fit(X_poly, y_values)\n",
        "y_poly_prediction = polynomial_model.predict(X_poly)\n",
        "poly_score = r2_score(y_values, y_poly_prediction)\n",
        "\n",
        "print(f'R squared with polynomial degree of {degree}: {poly_score:.5f}')"
      ],
      "id": "existing-three",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R squared (No polynomials): 0.88507\n",
            "\n",
            "0.8850713333142468\n",
            "R squared with polynomial degree of 4: 0.95211\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "balanced-saver",
        "outputId": "3c9792fc-a837-4a5f-b63d-1497b8128f5d"
      },
      "source": [
        "# K-Means Clustering\n",
        "import pandas as pd\n",
        "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_values, y_values, test_size = .33, random_state = random_state)\n",
        "i = 10\n",
        "model = KNeighborsRegressor(n_neighbors=i)\n",
        "model.fit(X_train, y_train.values.ravel())\n",
        "#print(model)\n",
        "#y_pred = model.predict(X_test)\n",
        "model_score = model.score(X_test, y_test)\n",
        "print(f'Model score with {i} neighbours: {model_score:.2f}')\n",
        "print('\\n'*10)\n",
        "'''\n",
        "best_score = 0\n",
        "for i in range (2,11):\n",
        "    model = KNeighborsClassifier(n_neighbors=i)\n",
        "    model.fit(X_train, y_train.values.ravel())\n",
        "    #print(model)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    #print(prediction)\n",
        "    model_score = model.score(X_test, y_test)\n",
        "    print(f'Model score with {i} neighbours: {model_score:.2f}')\n",
        "    if (model_score > best_score):\n",
        "        best_score = model_score\n",
        "        print(f'New best score:\\n{confusion_matrix(y_test, y_pred)}')\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_values, y_categorical['categories'], test_size = .33, random_state = random_state)\n",
        "\n",
        "for i in range (2,11):\n",
        "    model = KNeighborsClassifier(n_neighbors=i)\n",
        "    model.fit(X_train, y_train.values.ravel())\n",
        "    #print(model)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    #print(prediction)\n",
        "    model_score = model.score(X_test, y_test)\n",
        "    print(f'Categorical model score with {i} neighbours: {model_score:.2f}')\n",
        "    if (model_score > best_score):\n",
        "        best_score = model_score\n",
        "        print(f'New best score:\\n{confusion_matrix(y_test, y_pred)}')\n",
        "#'''"
      ],
      "id": "balanced-saver",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model score with 10 neighbours: 0.94\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nbest_score = 0\\nfor i in range (2,11):\\n    model = KNeighborsClassifier(n_neighbors=i)\\n    model.fit(X_train, y_train.values.ravel())\\n    #print(model)\\n    y_pred = model.predict(X_test)\\n\\n    #print(prediction)\\n    model_score = model.score(X_test, y_test)\\n    print(f'Model score with {i} neighbours: {model_score:.2f}')\\n    if (model_score > best_score):\\n        best_score = model_score\\n        print(f'New best score:\\n{confusion_matrix(y_test, y_pred)}')\\n\\nX_train, X_test, y_train, y_test = train_test_split(X_values, y_categorical['categories'], test_size = .33, random_state = random_state)\\n\\nfor i in range (2,11):\\n    model = KNeighborsClassifier(n_neighbors=i)\\n    model.fit(X_train, y_train.values.ravel())\\n    #print(model)\\n    y_pred = model.predict(X_test)\\n\\n    #print(prediction)\\n    model_score = model.score(X_test, y_test)\\n    print(f'Categorical model score with {i} neighbours: {model_score:.2f}')\\n    if (model_score > best_score):\\n        best_score = model_score\\n        print(f'New best score:\\n{confusion_matrix(y_test, y_pred)}')\\n#\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rocky-gazette",
        "outputId": "c8aaabfc-d5bc-4345-c2a0-7e7131a0d40c"
      },
      "source": [
        "# Neural Network\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_values, y_values, test_size = .33)\n",
        "\n",
        "scaling = StandardScaler().fit(X_train)\n",
        "X_train = scaling.transform(X_train)\n",
        "X_test = scaling.transform(X_test)\n",
        "\n",
        "hidden_layer_sizes = (10,20,40,80)\n",
        "nn_reg = MLPRegressor(max_iter=1000, hidden_layer_sizes = hidden_layer_sizes, activation='relu', solver='adam', random_state=random_state)\n",
        "\n",
        "nn_reg.fit(X_train, y_train.values.ravel())\n",
        "\n",
        "y_pred = nn_reg.predict(X_test)\n",
        "print(r2_score(y_test, y_pred))"
      ],
      "id": "rocky-gazette",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.943772889411137\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "foreign-movement",
        "outputId": "2d7d645f-2bee-4cb9-c4ac-07ea17b56b6b"
      },
      "source": [
        "#Support Vector Machine \n",
        "#Score: 0.7892253244199764 with C = 100\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X_values, y_categorical['categories'], test_size = .33, random_state = random_state)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_values, y_values, test_size = .33, random_state = random_state)\n",
        "#scaling = MinMaxScaler(feature_range=(0, 1)).fit(X_train)\n",
        "scaling = StandardScaler().fit(X_train)\n",
        "X_train = scaling.transform(X_train)\n",
        "X_test = scaling.transform(X_test)\n",
        "max_iter = 50000\n",
        "C = 30 #1000 = 0.865763641833894\n",
        "kernel = 'poly'#'rbf'#'linear'\n",
        "degree = 1\n",
        "#svm_model = SVC(shrinking = False, max_iter = max_iter, C=C, kernel=kernel, degree = degree, verbose = True, random_state = random_state)\n",
        "svm_model = SVR(max_iter = max_iter, C=C, kernel=kernel, degree = degree)\n",
        "svm_model.fit(X_train, y_train)\n",
        "#y_pred = svm_model.predict(X_test)\n",
        "print(svm_model.score(X_test, y_test))\n",
        "\n",
        "\n"
      ],
      "id": "foreign-movement",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8602540044756709\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "literary-europe",
        "outputId": "8e721d30-e795-4321-ab35-3ee1c9320737"
      },
      "source": [
        "# Ensemble - Random Forest Regressor\n",
        "# Score: 0.8795011516206954\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "'''\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_values, y_categorical['categories'], test_size = .33, random_state = random_state)\n",
        "scaling = MinMaxScaler(feature_range=(0, 1)).fit(X_train)\n",
        "n_estimators = 500\n",
        "n_jobs = 5\n",
        "ensemble_model = RandomForestClassifier(n_estimators = n_estimators, n_jobs = n_jobs)\n",
        "ensemble_model.fit(X_train, y_train)\n",
        "ensemble_model.predict(X_test)\n",
        "print(ensemble_model.score(X_test, y_test))\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "'''\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_values, y_values, test_size = .33, random_state = random_state)\n",
        "scaling = MinMaxScaler(feature_range=(0, 1)).fit(X_train)\n",
        "ensemble_model = RandomForestRegressor()\n",
        "ensemble_model.fit(X_train, y_train)\n",
        "y_pred = ensemble_model.predict(X_test)\n",
        "print(ensemble_model.score(X_test, y_test))"
      ],
      "id": "literary-europe",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9802118981430189\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}